Overview:
This project focuses on data analysis using PySpark on the Databricks platform, leveraging AWS for storage. The analysis includes various transformations and computations on a provided dataset.

System Setup:

Environment:

Ensure you have a Databricks environment set up.
Notebook Execution:

Upload the provided Jupyter notebook (NYPD_Arrests_Analysis.ipynb) to your Databricks workspace.
Dataset:

Download the NYPD Arrests dataset for the year 2023 from Dataset Link.
Upload the dataset to your Databricks workspace.
Databricks Configuration:

Adjust file paths in the notebook to match the location where you uploaded the dataset


Dependencies:

PySpark
Pandas
Matplotlib
Seaborn
Folium



Running the System:

1.) Open the notebook (Final_Proj_NYPD.ipynb) in Databricks.
2.) Execute the cells sequentially to load and analyze the dataset.
3.) Ensure all required libraries are installed. If not, install them using %pip install library_name.
4.) Customize parameters as needed (e.g., dataset paths, date formats).
5.) Run each cell to execute code blocks for data loading, cleaning, and analysis.
6.) Review visualizations and insights generated by the notebook.

Additional Information:

The notebook includes sections for:
Exploratory Data Analysis (EDA)
Temporal Analysis
Geospatial Analysis
Machine Learning (Random Forest Classifier)
Visualization of Results

Dataset Link:
https://catalog.data.gov/dataset/nypd-arrest-data-year-to-date



